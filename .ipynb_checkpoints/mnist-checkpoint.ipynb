{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Low Precision Training Example\n",
    "In this notebook, we present a quick example of how to simulate training a deep neural network in low precision with QPyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training MNIST in Floating Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import useful modules\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from qtorch.quant import Quantizer\n",
    "from qtorch.optim import OptimLP\n",
    "from torch.optim import SGD\n",
    "from qtorch import BlockFloatingPoint, FloatingPoint, FixedPoint\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load the data. In this example, we will experiment with MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loading data\n",
    "ds = torchvision.datasets.MNIST\n",
    "path = os.path.join(\"./data\", \"MNIST\")\n",
    "transform_train = transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))])\n",
    "transform_test = transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])\n",
    "train_set = ds(path, train=True, download=True, transform=transform_train)\n",
    "test_set = ds(path, train=False, download=True, transform=transform_test)\n",
    "loaders = {\n",
    "        'train': torch.utils.data.DataLoader(\n",
    "            train_set,\n",
    "            batch_size=64,\n",
    "            shuffle=True,\n",
    "            num_workers=1,\n",
    "            pin_memory=True\n",
    "        ),\n",
    "        'test': torch.utils.data.DataLoader(\n",
    "            test_set,\n",
    "            batch_size=64,\n",
    "            num_workers=1,\n",
    "            pin_memory=True\n",
    "        )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define the quantization setting we are going to use. We define a low and high precision format for different parts of the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define two floating point formats\n",
    "lowp = FixedPoint(wl=8, fl=7)\n",
    "highp = FloatingPoint(exp=8, man=7)  # this is bfloat16\n",
    "\n",
    "# define quantization functions\n",
    "weight_quant = Quantizer(forward_number=lowp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
    "grad_quant = Quantizer(forward_number=lowp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"stochastic\")\n",
    "momentum_quant = Quantizer(forward_number=highp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"stochastic\")\n",
    "acc_quant = Quantizer(forward_number=highp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
    "\n",
    "# define a lambda function so that the Quantizer module can be duplicated easily\n",
    "act_error_quant = lambda : Quantizer(forward_number=lowp, backward_number=lowp,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a simple LeNet network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define the model we are using\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use define the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = False\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = Net().to(device)\n",
    "optimizer = SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=1e-4)\n",
    "mxepochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(loader, model, criterion, optimizer=None, phase=\"train\"):\n",
    "    assert phase in [\"train\", \"eval\"], \"invalid running phase\"\n",
    "    loss_sum = 0.0\n",
    "    correct = 0.0\n",
    "\n",
    "    if phase==\"train\": model.train()\n",
    "    elif phase==\"eval\": model.eval()\n",
    "\n",
    "    ttl = 0\n",
    "    with torch.autograd.set_grad_enabled(phase==\"train\"):\n",
    "        for i, (input, target) in tqdm(enumerate(loader), total=len(loader)):\n",
    "            input = input.to(device=device)\n",
    "            target = target.to(device=device)\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "            loss_sum += loss.cpu().item() * input.size(0)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "            ttl += input.size()[0]\n",
    "\n",
    "            if phase==\"train\":\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "    correct = correct.cpu().item()\n",
    "    return {\n",
    "        'loss': loss_sum / float(ttl),\n",
    "        'accuracy': correct / float(ttl) * 100.0,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training in floating point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:39<00:00, 23.72it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "{'loss': 0.1548568486512949, 'accuracy': 95.30999999999999}\n",
      "{'loss': 0.05399869631174952, 'accuracy': 98.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [00:40<00:00, 23.02it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "{'loss': 0.050923540150087016, 'accuracy': 98.40666666666667}\n",
      "{'loss': 0.038043655622110234, 'accuracy': 98.85000000000001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [00:41<00:00, 22.53it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 59.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2\n",
      "{'loss': 0.03635380459926091, 'accuracy': 98.89666666666666}\n",
      "{'loss': 0.039981415704404936, 'accuracy': 98.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [00:40<00:00, 21.55it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 56.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3\n",
      "{'loss': 0.026738988577052564, 'accuracy': 99.20333333333333}\n",
      "{'loss': 0.03463587620096514, 'accuracy': 98.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [00:44<00:00, 21.10it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4\n",
      "{'loss': 0.02492401987304135, 'accuracy': 99.22166666666666}\n",
      "{'loss': 0.044022833132231605, 'accuracy': 98.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(mxepochs):\n",
    "    fp_train_res = run_epoch(loaders['train'], model, F.cross_entropy,\n",
    "                            optimizer=optimizer, phase=\"train\")\n",
    "    fp_test_res = run_epoch(loaders['test'], model, F.cross_entropy,\n",
    "                            optimizer=optimizer, phase=\"eval\")\n",
    "    print('epoch', epoch)\n",
    "    print(fp_train_res)\n",
    "    print(fp_test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Block Floating Point Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do it with low precision arithmetic. We first define the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define two number formats, one low precision the other high\n",
    "lowp = BlockFloatingPoint(wl=8, dim=-1)   \n",
    "highp = FloatingPoint(exp=8, man=7)      # this is bfloat16\n",
    "\n",
    "# define quantization functions\n",
    "weight_quant = Quantizer(forward_number=lowp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
    "grad_quant = Quantizer(forward_number=lowp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"stochastic\")\n",
    "momentum_quant = Quantizer(forward_number=highp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"stochastic\")\n",
    "acc_quant = Quantizer(forward_number=highp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
    "\n",
    "# define a lambda function so that the Quantizer module can be duplicated easily\n",
    "act_error_quant = lambda : Quantizer(forward_number=lowp, backward_number=lowp,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the network. In the definition, we insert quantization module after every convolution layer. Note that the quantization of weight, gradient, momentum, and gradient accumulator are not handled here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define the model we are using\n",
    "class lp_Net(nn.Module):\n",
    "    def __init__(self, quant=None):\n",
    "        super(lp_Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        self.quant = quant()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.quant(x)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = self.quant(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.quant(x)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = self.quant(x)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.quant(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.quant(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [02:30<00:00,  7.05it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 22.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "{'loss': 0.14877561846847334, 'accuracy': 95.46333333333334}\n",
      "{'loss': 0.055002218252327296, 'accuracy': 98.24000000000001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:26<00:00,  7.11it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "{'loss': 0.04905585635108873, 'accuracy': 98.53333333333333}\n",
      "{'loss': 0.04557450313158333, 'accuracy': 98.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:34<00:00,  7.02it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 22.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2\n",
      "{'loss': 0.03605607222200682, 'accuracy': 98.91499999999999}\n",
      "{'loss': 0.035946826914011035, 'accuracy': 98.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:27<00:00,  7.12it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 19.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3\n",
      "{'loss': 0.027282131382031366, 'accuracy': 99.13833333333332}\n",
      "{'loss': 0.039499994107394014, 'accuracy': 98.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:30<00:00,  6.09it/s]\n",
      "100%|██████████| 157/157 [00:08<00:00, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4\n",
      "{'loss': 0.022397064461020636, 'accuracy': 99.295}\n",
      "{'loss': 0.036419605036976284, 'accuracy': 98.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "use_cuda = False\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = lp_Net(act_error_quant).to(device)\n",
    "optimizer = SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=1e-4)\n",
    "lp_optimizer = OptimLP(optimizer,\n",
    "                    weight_quant=weight_quant,\n",
    "                    grad_quant=grad_quant,\n",
    "                    momentum_quant=momentum_quant,\n",
    "                    acc_quant=acc_quant\n",
    ")\n",
    "for epoch in range(mxepochs):\n",
    "    train_res = run_epoch(loaders['train'], model, F.cross_entropy,\n",
    "                                optimizer=lp_optimizer, phase=\"train\")\n",
    "    test_res = run_epoch(loaders['test'], model, F.cross_entropy,\n",
    "                                optimizer=lp_optimizer, phase=\"eval\")\n",
    "    print('epoch', epoch)\n",
    "    print(train_res)\n",
    "    print(test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Accuracy vs wordlength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, generate a plot of accuracy vs wordlength using the implementation given in the previous sections as a starting point. What precision gives the best accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute NN accuracy vs wordlength. Place appropriate code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 90.1), (2, 90.2), (3, 90.3), (4, 90.4), (5, 90.5), (6, 90.6), (7, 90.7), (8, 90.8)]\n"
     ]
    }
   ],
   "source": [
    "# dummy code here that just populates the res list\n",
    "res = []\n",
    "(minp, maxp) = (1,8)\n",
    "for i in range(minp, maxp+1):\n",
    "    res.append((i, 90 + i / 10))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a scatterplot of the results, also draw a line to show the floating point result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x125c8f668>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_res=np.array(res)\n",
    "plt.plot(plt_res[:,0], plt_res[:,1], 'x')\n",
    "plt.plot((minp,maxp),(fp_test_res['accuracy'], fp_test_res['accuracy']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total execution time (s): 1011.3039181232452\n"
     ]
    }
   ],
   "source": [
    "print(\"Total execution time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
