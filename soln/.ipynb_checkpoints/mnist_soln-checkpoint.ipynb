{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Low Precision Training Example\n",
    "In this notebook, we present a quick example of how to simulate training a deep neural network in low precision with QPyTorch. The (very small) MNIST data set is used as it is trainable in about 10 minutes on a notebook computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training MNIST in Floating Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import useful modules\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from qtorch.quant import Quantizer\n",
    "from qtorch.optim import OptimLP\n",
    "from torch.optim import SGD\n",
    "from qtorch import BlockFloatingPoint, FloatingPoint, FixedPoint\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record start time so we can time execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load the data. In this example, we will experiment with MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loading data\n",
    "ds = torchvision.datasets.MNIST\n",
    "path = os.path.join(\"./data\", \"MNIST\")\n",
    "transform_train = transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))])\n",
    "transform_test = transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])\n",
    "train_set = ds(path, train=True, download=True, transform=transform_train)\n",
    "test_set = ds(path, train=False, download=True, transform=transform_test)\n",
    "loaders = {\n",
    "        'train': torch.utils.data.DataLoader(\n",
    "            train_set,\n",
    "            batch_size=64,\n",
    "            shuffle=True,\n",
    "            num_workers=1,\n",
    "            pin_memory=True\n",
    "        ),\n",
    "        'test': torch.utils.data.DataLoader(\n",
    "            test_set,\n",
    "            batch_size=64,\n",
    "            num_workers=1,\n",
    "            pin_memory=True\n",
    "        )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define the quantization setting we are going to use. We define a low and high precision format for different parts of the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define two floating point formats\n",
    "lowp = FixedPoint(wl=8, fl=7)\n",
    "highp = FloatingPoint(exp=8, man=7)  # this is bfloat16\n",
    "\n",
    "# define quantization functions\n",
    "weight_quant = Quantizer(forward_number=lowp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
    "grad_quant = Quantizer(forward_number=lowp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"stochastic\")\n",
    "momentum_quant = Quantizer(forward_number=highp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"stochastic\")\n",
    "acc_quant = Quantizer(forward_number=highp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
    "\n",
    "# define a lambda function so that the Quantizer module can be duplicated easily\n",
    "act_error_quant = lambda : Quantizer(forward_number=lowp, backward_number=lowp,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a simple LeNet network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define the model we are using\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the low-precision optimizer wrapper to help define the quantization of weight, gradient, momentum, and gradient accumulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = False\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = Net().to(device)\n",
    "optimizer = SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=1e-4)\n",
    "mxepochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reuse common training scripts without any extra codes to handle quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(loader, model, criterion, optimizer=None, phase=\"train\"):\n",
    "    assert phase in [\"train\", \"eval\"], \"invalid running phase\"\n",
    "    loss_sum = 0.0\n",
    "    correct = 0.0\n",
    "\n",
    "    if phase==\"train\": model.train()\n",
    "    elif phase==\"eval\": model.eval()\n",
    "\n",
    "    ttl = 0\n",
    "    with torch.autograd.set_grad_enabled(phase==\"train\"):\n",
    "        for i, (input, target) in tqdm(enumerate(loader), total=len(loader)):\n",
    "            input = input.to(device=device)\n",
    "            target = target.to(device=device)\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "            loss_sum += loss.cpu().item() * input.size(0)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "            ttl += input.size()[0]\n",
    "\n",
    "            if phase==\"train\":\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "    correct = correct.cpu().item()\n",
    "    return {\n",
    "        'loss': loss_sum / float(ttl),\n",
    "        'accuracy': correct / float(ttl) * 100.0,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training in floating point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:33<00:00, 27.77it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 83.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "{'loss': 0.13367664850832273, 'accuracy': 95.84}\n",
      "{'loss': 0.0727696247242391, 'accuracy': 97.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [00:32<00:00, 28.60it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 81.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "{'loss': 0.04448821579326565, 'accuracy': 98.62166666666667}\n",
      "{'loss': 0.04107394484523684, 'accuracy': 98.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [00:32<00:00, 29.02it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 84.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2\n",
      "{'loss': 0.03161305730418147, 'accuracy': 99.04166666666666}\n",
      "{'loss': 0.0346707621938549, 'accuracy': 98.92999999999999}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [00:32<00:00, 29.11it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 83.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3\n",
      "{'loss': 0.02504964566466321, 'accuracy': 99.265}\n",
      "{'loss': 0.035839459211647044, 'accuracy': 98.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [00:32<00:00, 29.00it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 84.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4\n",
      "{'loss': 0.018071174771644292, 'accuracy': 99.43166666666666}\n",
      "{'loss': 0.04211554967815464, 'accuracy': 98.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(mxepochs):\n",
    "    fp_train_res = run_epoch(loaders['train'], model, F.cross_entropy,\n",
    "                            optimizer=optimizer, phase=\"train\")\n",
    "    fp_test_res = run_epoch(loaders['test'], model, F.cross_entropy,\n",
    "                            optimizer=optimizer, phase=\"eval\")\n",
    "    print('epoch', epoch)\n",
    "    print(fp_train_res)\n",
    "    print(fp_test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Block Floating Point Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do it with quantized arithmetic. We first define the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define two floating point formats\n",
    "lowp = BlockFloatingPoint(wl=8, dim=-1)   \n",
    "highp = FloatingPoint(exp=8, man=7)      # this is bfloat16\n",
    "\n",
    "# define quantization functions\n",
    "weight_quant = Quantizer(forward_number=lowp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
    "grad_quant = Quantizer(forward_number=lowp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"stochastic\")\n",
    "momentum_quant = Quantizer(forward_number=highp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"stochastic\")\n",
    "acc_quant = Quantizer(forward_number=highp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
    "\n",
    "# define a lambda function so that the Quantizer module can be duplicated easily\n",
    "act_error_quant = lambda : Quantizer(forward_number=lowp, backward_number=lowp,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the network. In the definition, we insert quantization module after every convolution layer. Note that the quantization of weight, gradient, momentum, and gradient accumulator are not handled here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define the model we are using\n",
    "class lp_Net(nn.Module):\n",
    "    def __init__(self, quant=None):\n",
    "        super(lp_Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        self.quant = quant()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.quant(x)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = self.quant(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.quant(x)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = self.quant(x)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.quant(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.quant(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [02:06<00:00,  7.80it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 26.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "{'loss': 0.14198540433980525, 'accuracy': 95.65}\n",
      "{'loss': 0.05083054470997304, 'accuracy': 98.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:06<00:00,  7.44it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 26.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "{'loss': 0.049432920107307536, 'accuracy': 98.49166666666666}\n",
      "{'loss': 0.03558836102850037, 'accuracy': 98.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:07<00:00,  7.35it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 26.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2\n",
      "{'loss': 0.03405739075575645, 'accuracy': 98.94}\n",
      "{'loss': 0.037626516264607196, 'accuracy': 98.96000000000001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:07<00:00,  7.34it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 26.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3\n",
      "{'loss': 0.02557014290516187, 'accuracy': 99.19333333333333}\n",
      "{'loss': 0.03396214326859918, 'accuracy': 98.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:04<00:00,  7.53it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4\n",
      "{'loss': 0.022800768085871823, 'accuracy': 99.275}\n",
      "{'loss': 0.034088476684188934, 'accuracy': 98.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "use_cuda = False\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = lp_Net(act_error_quant).to(device)\n",
    "optimizer = SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=1e-4)\n",
    "lp_optimizer = OptimLP(optimizer,\n",
    "                    weight_quant=weight_quant,\n",
    "                    grad_quant=grad_quant,\n",
    "                    momentum_quant=momentum_quant,\n",
    "                    acc_quant=acc_quant\n",
    ")\n",
    "for epoch in range(mxepochs):\n",
    "    train_res = run_epoch(loaders['train'], model, F.cross_entropy,\n",
    "                                optimizer=lp_optimizer, phase=\"train\")\n",
    "    test_res = run_epoch(loaders['test'], model, F.cross_entropy,\n",
    "                                optimizer=lp_optimizer, phase=\"eval\")\n",
    "    print('epoch', epoch)\n",
    "    print(train_res)\n",
    "    print(test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Accuracy vs wordlength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First include some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute NN accuracy vs wordlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [02:06<00:00,  7.43it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 1 epoch 0\n",
      "{'loss': 2.449473961766561, 'accuracy': 10.213333333333335}\n",
      "{'loss': 2.3025834590911867, 'accuracy': 10.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:05<00:00,  7.49it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 1 epoch 1\n",
      "{'loss': 2.9238441473642984, 'accuracy': 9.91}\n",
      "{'loss': 2.556058658218384, 'accuracy': 10.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:04<00:00,  7.55it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 1 epoch 2\n",
      "{'loss': 2.498283224105835, 'accuracy': 9.915000000000001}\n",
      "{'loss': 2.3025834590911867, 'accuracy': 10.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:04<00:00,  7.53it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 26.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 1 epoch 3\n",
      "{'loss': 2.302583456802368, 'accuracy': 9.915000000000001}\n",
      "{'loss': 2.3025834590911867, 'accuracy': 10.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:03<00:00,  7.58it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 1 epoch 4\n",
      "{'loss': 2.302583456802368, 'accuracy': 9.915000000000001}\n",
      "{'loss': 2.3025834590911867, 'accuracy': 10.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:06<00:00,  7.42it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 2 epoch 0\n",
      "{'loss': nan, 'accuracy': 9.923333333333334}\n",
      "{'loss': nan, 'accuracy': 9.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:08<00:00,  7.32it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 2 epoch 1\n",
      "{'loss': nan, 'accuracy': 9.871666666666666}\n",
      "{'loss': nan, 'accuracy': 9.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:05<00:00,  7.45it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 29.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 2 epoch 2\n",
      "{'loss': nan, 'accuracy': 9.871666666666666}\n",
      "{'loss': nan, 'accuracy': 9.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:02<00:00,  7.65it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 29.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 2 epoch 3\n",
      "{'loss': nan, 'accuracy': 9.871666666666666}\n",
      "{'loss': nan, 'accuracy': 9.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:02<00:00,  7.64it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 29.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 2 epoch 4\n",
      "{'loss': nan, 'accuracy': 9.871666666666666}\n",
      "{'loss': nan, 'accuracy': 9.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:00<00:00,  7.75it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 28.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 3 epoch 0\n",
      "{'loss': 3.0691015096028647, 'accuracy': 9.966666666666667}\n",
      "{'loss': 2.3025834590911867, 'accuracy': 10.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:01<00:00,  7.69it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 28.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 3 epoch 1\n",
      "{'loss': 3.0123214944203696, 'accuracy': 9.925}\n",
      "{'loss': 2.3025834590911867, 'accuracy': 10.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:01<00:00,  7.69it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 3 epoch 2\n",
      "{'loss': 2.6627651859283445, 'accuracy': 10.058333333333334}\n",
      "{'loss': 2.3025834590911867, 'accuracy': 10.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:01<00:00,  7.72it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 28.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 3 epoch 3\n",
      "{'loss': 2.302583456802368, 'accuracy': 9.915000000000001}\n",
      "{'loss': 2.3025834590911867, 'accuracy': 10.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:01<00:00,  7.71it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 28.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 3 epoch 4\n",
      "{'loss': 2.302583456802368, 'accuracy': 9.915000000000001}\n",
      "{'loss': 2.3025834590911867, 'accuracy': 10.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:02<00:00,  8.21it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 28.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 4 epoch 0\n",
      "{'loss': 1.2549087883313497, 'accuracy': 55.68333333333333}\n",
      "{'loss': 2.075331261444092, 'accuracy': 28.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:04<00:00,  7.56it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 29.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 4 epoch 1\n",
      "{'loss': 2.010598845545451, 'accuracy': 25.271666666666665}\n",
      "{'loss': 2.3540779685974123, 'accuracy': 10.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:03<00:00,  7.62it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 26.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 4 epoch 2\n",
      "{'loss': 2.4344181752522784, 'accuracy': 10.13}\n",
      "{'loss': 2.362824640655518, 'accuracy': 10.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:23<00:00,  6.52it/s]\n",
      "100%|██████████| 157/157 [00:06<00:00, 25.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 4 epoch 3\n",
      "{'loss': 2.345832378768921, 'accuracy': 9.895}\n",
      "{'loss': 2.3025834590911867, 'accuracy': 10.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:13<00:00,  7.01it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 29.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 4 epoch 4\n",
      "{'loss': 2.15802568581899, 'accuracy': 18.243333333333332}\n",
      "{'loss': 1.8852229196548462, 'accuracy': 31.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:10<00:00,  7.18it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 5 epoch 0\n",
      "{'loss': 0.17361977825413147, 'accuracy': 94.57833333333333}\n",
      "{'loss': 0.0741601131618023, 'accuracy': 97.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:10<00:00,  7.19it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 28.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 5 epoch 1\n",
      "{'loss': 0.0828573593750596, 'accuracy': 97.32166666666666}\n",
      "{'loss': 0.08051453416720032, 'accuracy': 97.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:11<00:00,  7.11it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 28.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 5 epoch 2\n",
      "{'loss': 0.07803381388535102, 'accuracy': 97.47}\n",
      "{'loss': 0.06764264784678817, 'accuracy': 97.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:12<00:00,  7.11it/s]\n",
      "100%|██████████| 157/157 [00:06<00:00, 25.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 5 epoch 3\n",
      "{'loss': 0.07839758532742659, 'accuracy': 97.49}\n",
      "{'loss': 0.09697388264685869, 'accuracy': 96.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:04<00:00,  7.51it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 5 epoch 4\n",
      "{'loss': 0.07327056730091572, 'accuracy': 97.60833333333333}\n",
      "{'loss': 0.08843653662279248, 'accuracy': 97.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:04<00:00,  7.51it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 6 epoch 0\n",
      "{'loss': 0.13953491156076392, 'accuracy': 95.56333333333333}\n",
      "{'loss': 0.05019461778178811, 'accuracy': 98.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:06<00:00,  7.40it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 6 epoch 1\n",
      "{'loss': 0.04960837741326541, 'accuracy': 98.45833333333334}\n",
      "{'loss': 0.04006253944686614, 'accuracy': 98.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:07<00:00,  7.35it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 6 epoch 2\n",
      "{'loss': 0.03616402240634586, 'accuracy': 98.81166666666667}\n",
      "{'loss': 0.03565585003169253, 'accuracy': 98.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:32<00:00,  7.00it/s]\n",
      "100%|██████████| 157/157 [00:08<00:00, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 6 epoch 3\n",
      "{'loss': 0.030261270309891553, 'accuracy': 99.03333333333333}\n",
      "{'loss': 0.036098808926483615, 'accuracy': 98.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:41<00:00,  6.94it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 19.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 6 epoch 4\n",
      "{'loss': 0.026812411448871715, 'accuracy': 99.11833333333333}\n",
      "{'loss': 0.035926506285299545, 'accuracy': 98.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:27<00:00,  7.21it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 7 epoch 0\n",
      "{'loss': 0.13072832972283166, 'accuracy': 95.96166666666667}\n",
      "{'loss': 0.05778304645866156, 'accuracy': 98.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:27<00:00,  6.87it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 7 epoch 1\n",
      "{'loss': 0.043071390505476544, 'accuracy': 98.66}\n",
      "{'loss': 0.03219916624862235, 'accuracy': 99.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:34<00:00,  7.14it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 22.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 7 epoch 2\n",
      "{'loss': 0.03221419487517948, 'accuracy': 98.965}\n",
      "{'loss': 0.037017335840221495, 'accuracy': 98.92999999999999}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:29<00:00,  7.17it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 7 epoch 3\n",
      "{'loss': 0.023635286369578293, 'accuracy': 99.21666666666667}\n",
      "{'loss': 0.02959721099907183, 'accuracy': 99.03999999999999}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:22<00:00,  6.56it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 7 epoch 4\n",
      "{'loss': 0.018859537652348324, 'accuracy': 99.37666666666667}\n",
      "{'loss': 0.03445335301676823, 'accuracy': 98.85000000000001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:10<00:00,  7.21it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 8 epoch 0\n",
      "{'loss': 0.1410763572932221, 'accuracy': 95.65833333333333}\n",
      "{'loss': 0.047613590149767696, 'accuracy': 98.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:07<00:00,  7.36it/s]\n",
      "100%|██████████| 157/157 [00:06<00:00, 25.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 8 epoch 1\n",
      "{'loss': 0.04550401421322798, 'accuracy': 98.65166666666667}\n",
      "{'loss': 0.03821977791737299, 'accuracy': 98.85000000000001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:08<00:00,  7.30it/s]\n",
      "100%|██████████| 157/157 [00:06<00:00, 25.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 8 epoch 2\n",
      "{'loss': 0.03281782499829618, 'accuracy': 98.93666666666667}\n",
      "{'loss': 0.0513253887694038, 'accuracy': 98.50999999999999}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:07<00:00,  7.37it/s]\n",
      "100%|██████████| 157/157 [00:06<00:00, 24.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 8 epoch 3\n",
      "{'loss': 0.027139872623809302, 'accuracy': 99.17833333333334}\n",
      "{'loss': 0.03683581567425281, 'accuracy': 98.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:10<00:00,  7.20it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 26.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 8 epoch 4\n",
      "{'loss': 0.02112162397536449, 'accuracy': 99.33}\n",
      "{'loss': 0.038827422360423955, 'accuracy': 98.79}\n",
      "[(1, 10.09), (2, 9.8), (3, 10.09), (4, 31.91), (5, 97.41), (6, 98.91), (7, 98.85000000000001), (8, 98.79)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "(minp, maxp) = (1,8)\n",
    "for wl in range(minp, maxp+1):\n",
    "    # define two floating point formats\n",
    "    lowp = BlockFloatingPoint(wl=wl, dim=-1)   \n",
    "    highp = FloatingPoint(exp=8, man=7)      # this is bfloat16\n",
    "\n",
    "    # define quantization functions\n",
    "    weight_quant = Quantizer(forward_number=lowp, backward_number=None,\n",
    "                            forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
    "    grad_quant = Quantizer(forward_number=lowp, backward_number=None,\n",
    "                            forward_rounding=\"nearest\", backward_rounding=\"stochastic\")\n",
    "    momentum_quant = Quantizer(forward_number=highp, backward_number=None,\n",
    "                            forward_rounding=\"nearest\", backward_rounding=\"stochastic\")\n",
    "    acc_quant = Quantizer(forward_number=highp, backward_number=None,\n",
    "                            forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
    "\n",
    "    # define a lambda function so that the Quantizer module can be duplicated easily\n",
    "    act_error_quant = lambda : Quantizer(forward_number=lowp, backward_number=lowp,\n",
    "                            forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
    "    use_cuda = False\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    model = lp_Net(act_error_quant).to(device)\n",
    "    optimizer = SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=1e-4)\n",
    "    lp_optimizer = OptimLP(optimizer,\n",
    "                        weight_quant=weight_quant,\n",
    "                        grad_quant=grad_quant,\n",
    "                        momentum_quant=momentum_quant,\n",
    "                        acc_quant=acc_quant\n",
    "    )\n",
    "    for epoch in range(mxepochs):\n",
    "        train_res = run_epoch(loaders['train'], model, F.cross_entropy,\n",
    "                                    optimizer=lp_optimizer, phase=\"train\")\n",
    "        test_res = run_epoch(loaders['test'], model, F.cross_entropy,\n",
    "                                    optimizer=lp_optimizer, phase=\"eval\")\n",
    "        print('wl', wl, 'epoch', epoch)\n",
    "        print(train_res)\n",
    "        print(test_res)\n",
    "        \n",
    "    # make scatterplot\n",
    "    res.append((wl, test_res['accuracy']))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a scatterplot of the results, also draw a line to show the bfloat16 result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1204ca6d8>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_res=np.array(res)\n",
    "plt.plot(plt_res[:,0], plt_res[:,1], 'x')\n",
    "plt.plot((minp,maxp),(fp_test_res['accuracy'], fp_test_res['accuracy']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total execution time (s): 6313.812933921814\n"
     ]
    }
   ],
   "source": [
    "print(\"Total execution time (s):\", time.time() - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
