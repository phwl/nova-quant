{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Low Precision Training Example\n",
    "In this notebook, we present a quick example of how to simulate training a deep neural network in low precision with QPyTorch. The (very small) MNIST data set is used as it is trainable in about 10 minutes on a notebook computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training MNIST in Floating Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import useful modules\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from qtorch.quant import Quantizer\n",
    "from qtorch.optim import OptimLP\n",
    "from torch.optim import SGD\n",
    "from qtorch import BlockFloatingPoint, FloatingPoint, FixedPoint\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record start time so we can time execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load the data. In this example, we will experiment with MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loading data\n",
    "ds = torchvision.datasets.MNIST\n",
    "path = os.path.join(\"./data\", \"MNIST\")\n",
    "transform_train = transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))])\n",
    "transform_test = transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])\n",
    "train_set = ds(path, train=True, download=True, transform=transform_train)\n",
    "test_set = ds(path, train=False, download=True, transform=transform_test)\n",
    "loaders = {\n",
    "        'train': torch.utils.data.DataLoader(\n",
    "            train_set,\n",
    "            batch_size=64,\n",
    "            shuffle=True,\n",
    "            num_workers=1,\n",
    "            pin_memory=True\n",
    "        ),\n",
    "        'test': torch.utils.data.DataLoader(\n",
    "            test_set,\n",
    "            batch_size=64,\n",
    "            num_workers=1,\n",
    "            pin_memory=True\n",
    "        )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define the quantization setting we are going to use. We define a low and high precision format for different parts of the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define two floating point formats\n",
    "lowp = FixedPoint(wl=8, fl=7)\n",
    "highp = FloatingPoint(exp=8, man=7)  # this is bfloat16\n",
    "\n",
    "# define quantization functions\n",
    "weight_quant = Quantizer(forward_number=lowp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
    "grad_quant = Quantizer(forward_number=lowp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"stochastic\")\n",
    "momentum_quant = Quantizer(forward_number=highp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"stochastic\")\n",
    "acc_quant = Quantizer(forward_number=highp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
    "\n",
    "# define a lambda function so that the Quantizer module can be duplicated easily\n",
    "act_error_quant = lambda : Quantizer(forward_number=lowp, backward_number=lowp,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a simple LeNet network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define the model we are using\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the low-precision optimizer wrapper to help define the quantization of weight, gradient, momentum, and gradient accumulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = False\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = Net().to(device)\n",
    "optimizer = SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=1e-4)\n",
    "mxepochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reuse common training scripts without any extra codes to handle quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(loader, model, criterion, optimizer=None, phase=\"train\"):\n",
    "    assert phase in [\"train\", \"eval\"], \"invalid running phase\"\n",
    "    loss_sum = 0.0\n",
    "    correct = 0.0\n",
    "\n",
    "    if phase==\"train\": model.train()\n",
    "    elif phase==\"eval\": model.eval()\n",
    "\n",
    "    ttl = 0\n",
    "    with torch.autograd.set_grad_enabled(phase==\"train\"):\n",
    "        for i, (input, target) in tqdm(enumerate(loader), total=len(loader)):\n",
    "            input = input.to(device=device)\n",
    "            target = target.to(device=device)\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "            loss_sum += loss.cpu().item() * input.size(0)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "            ttl += input.size()[0]\n",
    "\n",
    "            if phase==\"train\":\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "    correct = correct.cpu().item()\n",
    "    return {\n",
    "        'loss': loss_sum / float(ttl),\n",
    "        'accuracy': correct / float(ttl) * 100.0,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training in floating point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:34<00:00, 26.82it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 82.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "{'loss': 0.13975346226207913, 'accuracy': 95.67833333333333}\n",
      "{'loss': 0.048652271528047276, 'accuracy': 98.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [00:32<00:00, 28.81it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 84.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "{'loss': 0.04398178725702067, 'accuracy': 98.6}\n",
      "{'loss': 0.02990385150157963, 'accuracy': 99.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [00:32<00:00, 28.87it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 89.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2\n",
      "{'loss': 0.03272670375339997, 'accuracy': 98.97166666666666}\n",
      "{'loss': 0.037594826527242546, 'accuracy': 98.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [00:33<00:00, 27.78it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 78.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3\n",
      "{'loss': 0.02493680008233253, 'accuracy': 99.20333333333333}\n",
      "{'loss': 0.03149537170268013, 'accuracy': 99.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [00:33<00:00, 28.12it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 80.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4\n",
      "{'loss': 0.020724476177947752, 'accuracy': 99.36500000000001}\n",
      "{'loss': 0.03945704701770155, 'accuracy': 98.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [00:33<00:00, 28.33it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 85.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5\n",
      "{'loss': 0.015872756416495153, 'accuracy': 99.49166666666667}\n",
      "{'loss': 0.03982625451160675, 'accuracy': 98.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [00:32<00:00, 28.67it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 84.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6\n",
      "{'loss': 0.012929226745905666, 'accuracy': 99.55833333333334}\n",
      "{'loss': 0.033759961486868634, 'accuracy': 99.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [00:32<00:00, 28.81it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 85.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7\n",
      "{'loss': 0.012680374797104257, 'accuracy': 99.6}\n",
      "{'loss': 0.03555196945745847, 'accuracy': 99.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [00:35<00:00, 26.65it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 78.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8\n",
      "{'loss': 0.011234540776508645, 'accuracy': 99.64}\n",
      "{'loss': 0.035852644269423764, 'accuracy': 99.00999999999999}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [00:35<00:00, 26.37it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 81.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9\n",
      "{'loss': 0.01165138601524324, 'accuracy': 99.60333333333334}\n",
      "{'loss': 0.032838685022593565, 'accuracy': 99.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(mxepochs):\n",
    "    fp_train_res = run_epoch(loaders['train'], model, F.cross_entropy,\n",
    "                            optimizer=optimizer, phase=\"train\")\n",
    "    fp_test_res = run_epoch(loaders['test'], model, F.cross_entropy,\n",
    "                            optimizer=optimizer, phase=\"eval\")\n",
    "    print('epoch', epoch)\n",
    "    print(fp_train_res)\n",
    "    print(fp_test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Block Floating Point Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do it with quantized arithmetic. We first define the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define two floating point formats\n",
    "lowp = BlockFloatingPoint(wl=8, dim=-1)   \n",
    "highp = FloatingPoint(exp=8, man=7)      # this is bfloat16\n",
    "\n",
    "# define quantization functions\n",
    "weight_quant = Quantizer(forward_number=lowp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
    "grad_quant = Quantizer(forward_number=lowp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"stochastic\")\n",
    "momentum_quant = Quantizer(forward_number=highp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"stochastic\")\n",
    "acc_quant = Quantizer(forward_number=highp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
    "\n",
    "# define a lambda function so that the Quantizer module can be duplicated easily\n",
    "act_error_quant = lambda : Quantizer(forward_number=lowp, backward_number=lowp,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the network. In the definition, we insert quantization module after every convolution layer. Note that the quantization of weight, gradient, momentum, and gradient accumulator are not handled here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define the model we are using\n",
    "class lp_Net(nn.Module):\n",
    "    def __init__(self, quant=None):\n",
    "        super(lp_Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        self.quant = quant()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.quant(x)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = self.quant(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.quant(x)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = self.quant(x)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.quant(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.quant(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [02:34<00:00,  6.46it/s]\n",
      "100%|██████████| 157/157 [00:08<00:00, 17.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "{'loss': 0.134907551719745, 'accuracy': 95.73166666666667}\n",
      "{'loss': 0.11002362940609454, 'accuracy': 96.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:25<00:00,  6.46it/s]\n",
      "100%|██████████| 157/157 [00:06<00:00, 26.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "{'loss': 0.0475153127261127, 'accuracy': 98.55333333333334}\n",
      "{'loss': 0.04490658403052948, 'accuracy': 98.55000000000001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:09<00:00,  7.24it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 28.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2\n",
      "{'loss': 0.03311258720730742, 'accuracy': 98.985}\n",
      "{'loss': 0.035893300364725295, 'accuracy': 98.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:05<00:00,  7.47it/s]\n",
      "100%|██████████| 157/157 [00:06<00:00, 24.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3\n",
      "{'loss': 0.02580145928617567, 'accuracy': 99.18}\n",
      "{'loss': 0.0380030062812788, 'accuracy': 98.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:08<00:00,  7.30it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4\n",
      "{'loss': 0.02097408466776833, 'accuracy': 99.34333333333333}\n",
      "{'loss': 0.03383344763555724, 'accuracy': 99.05000000000001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:04<00:00,  7.55it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5\n",
      "{'loss': 0.01713064722112031, 'accuracy': 99.44666666666667}\n",
      "{'loss': 0.02794512863709533, 'accuracy': 99.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:03<00:00,  7.57it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 28.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6\n",
      "{'loss': 0.016992174969456392, 'accuracy': 99.44166666666666}\n",
      "{'loss': 0.03320048576105037, 'accuracy': 99.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:07<00:00,  7.33it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7\n",
      "{'loss': 0.010031001010301407, 'accuracy': 99.67}\n",
      "{'loss': 0.03418132924698075, 'accuracy': 99.03999999999999}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:01<00:00,  7.70it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 28.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8\n",
      "{'loss': 0.008979617804124184, 'accuracy': 99.72166666666666}\n",
      "{'loss': 0.03690760707998743, 'accuracy': 99.03999999999999}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:19<00:00,  6.74it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9\n",
      "{'loss': 0.006913615543941948, 'accuracy': 99.78833333333334}\n",
      "{'loss': 0.03011619034334435, 'accuracy': 99.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "use_cuda = False\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = lp_Net(act_error_quant).to(device)\n",
    "optimizer = SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=1e-4)\n",
    "lp_optimizer = OptimLP(optimizer,\n",
    "                    weight_quant=weight_quant,\n",
    "                    grad_quant=grad_quant,\n",
    "                    momentum_quant=momentum_quant,\n",
    "                    acc_quant=acc_quant\n",
    ")\n",
    "for epoch in range(mxepochs):\n",
    "    train_res = run_epoch(loaders['train'], model, F.cross_entropy,\n",
    "                                optimizer=lp_optimizer, phase=\"train\")\n",
    "    test_res = run_epoch(loaders['test'], model, F.cross_entropy,\n",
    "                                optimizer=lp_optimizer, phase=\"eval\")\n",
    "    print('epoch', epoch)\n",
    "    print(train_res)\n",
    "    print(test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Accuracy vs wordlength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First include some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute NN accuracy vs wordlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [02:04<00:00,  7.56it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 28.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 1 epoch 0\n",
      "{'loss': 2.459815688451131, 'accuracy': 10.183333333333334}\n",
      "{'loss': 2.3025834590911867, 'accuracy': 10.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [05:07<00:00,  3.05it/s]  \n",
      "100%|██████████| 157/157 [00:05<00:00, 27.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 1 epoch 1\n",
      "{'loss': 2.995434170659383, 'accuracy': 9.975000000000001}\n",
      "{'loss': 2.556058658218384, 'accuracy': 10.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:10<00:00,  7.21it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 28.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wl 1 epoch 2\n",
      "{'loss': 2.4692039801279706, 'accuracy': 9.915000000000001}\n",
      "{'loss': 2.3025834590911867, 'accuracy': 10.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "(minp, maxp) = (1,8)\n",
    "for wl in range(minp, maxp+1):\n",
    "    # define two floating point formats\n",
    "    lowp = BlockFloatingPoint(wl=wl, dim=-1)   \n",
    "    highp = FloatingPoint(exp=8, man=7)      # this is bfloat16\n",
    "\n",
    "    # define quantization functions\n",
    "    weight_quant = Quantizer(forward_number=lowp, backward_number=None,\n",
    "                            forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
    "    grad_quant = Quantizer(forward_number=lowp, backward_number=None,\n",
    "                            forward_rounding=\"nearest\", backward_rounding=\"stochastic\")\n",
    "    momentum_quant = Quantizer(forward_number=highp, backward_number=None,\n",
    "                            forward_rounding=\"nearest\", backward_rounding=\"stochastic\")\n",
    "    acc_quant = Quantizer(forward_number=highp, backward_number=None,\n",
    "                            forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
    "\n",
    "    # define a lambda function so that the Quantizer module can be duplicated easily\n",
    "    act_error_quant = lambda : Quantizer(forward_number=lowp, backward_number=lowp,\n",
    "                            forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
    "    use_cuda = False\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    model = lp_Net(act_error_quant).to(device)\n",
    "    optimizer = SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=1e-4)\n",
    "    lp_optimizer = OptimLP(optimizer,\n",
    "                        weight_quant=weight_quant,\n",
    "                        grad_quant=grad_quant,\n",
    "                        momentum_quant=momentum_quant,\n",
    "                        acc_quant=acc_quant\n",
    "    )\n",
    "    for epoch in range(mxepochs):\n",
    "        train_res = run_epoch(loaders['train'], model, F.cross_entropy,\n",
    "                                    optimizer=lp_optimizer, phase=\"train\")\n",
    "        test_res = run_epoch(loaders['test'], model, F.cross_entropy,\n",
    "                                    optimizer=lp_optimizer, phase=\"eval\")\n",
    "        print('wl', wl, 'epoch', epoch)\n",
    "        print(train_res)\n",
    "        print(test_res)\n",
    "        \n",
    "    # make scatterplot\n",
    "    res.append((wl, test_res['accuracy']))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a scatterplot of the results, also draw a line to show the bfloat16 result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_res=np.array(res)\n",
    "plt.plot(plt_res[:,0], plt_res[:,1], 'x')\n",
    "plt.plot((minp,maxp),(fp_test_res['accuracy'], fp_test_res['accuracy']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total execution time (s):\", time.time() - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
