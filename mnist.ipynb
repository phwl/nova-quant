{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Low Precision Training Example\n",
    "In this notebook, we present a quick example of how to simulate training a deep neural network in low precision with QPyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training MNIST in Floating Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import useful modules\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from qtorch.quant import Quantizer\n",
    "from qtorch.optim import OptimLP\n",
    "from torch.optim import SGD\n",
    "from qtorch import BlockFloatingPoint, FloatingPoint, FixedPoint\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load the data. In this example, we will experiment with MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:01, 6392511.43it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28881 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 120619.63it/s]           \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:00, 1829725.64it/s]                            \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8192it [00:00, 45532.08it/s]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# loading data\n",
    "ds = torchvision.datasets.MNIST\n",
    "path = os.path.join(\"./data\", \"MNIST\")\n",
    "transform_train = transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))])\n",
    "transform_test = transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])\n",
    "train_set = ds(path, train=True, download=True, transform=transform_train)\n",
    "test_set = ds(path, train=False, download=True, transform=transform_test)\n",
    "loaders = {\n",
    "        'train': torch.utils.data.DataLoader(\n",
    "            train_set,\n",
    "            batch_size=64,\n",
    "            shuffle=True,\n",
    "            num_workers=1,\n",
    "            pin_memory=True\n",
    "        ),\n",
    "        'test': torch.utils.data.DataLoader(\n",
    "            test_set,\n",
    "            batch_size=64,\n",
    "            num_workers=1,\n",
    "            pin_memory=True\n",
    "        )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define the quantization setting we are going to use. We define a low and high precision format for different parts of the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define two floating point formats\n",
    "lowp = FixedPoint(wl=8, fl=7)\n",
    "highp = FloatingPoint(exp=8, man=7)  # this is bfloat16\n",
    "\n",
    "# define quantization functions\n",
    "weight_quant = Quantizer(forward_number=lowp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
    "grad_quant = Quantizer(forward_number=lowp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"stochastic\")\n",
    "momentum_quant = Quantizer(forward_number=highp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"stochastic\")\n",
    "acc_quant = Quantizer(forward_number=highp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
    "\n",
    "# define a lambda function so that the Quantizer module can be duplicated easily\n",
    "act_error_quant = lambda : Quantizer(forward_number=lowp, backward_number=lowp,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a simple LeNet network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define the model we are using\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the low-precision optimizer wrapper to help define the quantization of weight, gradient, momentum, and gradient accumulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = False\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = Net().to(device)\n",
    "optimizer = SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=1e-4)\n",
    "mxepochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reuse common training scripts without any extra codes to handle quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(loader, model, criterion, optimizer=None, phase=\"train\"):\n",
    "    assert phase in [\"train\", \"eval\"], \"invalid running phase\"\n",
    "    loss_sum = 0.0\n",
    "    correct = 0.0\n",
    "\n",
    "    if phase==\"train\": model.train()\n",
    "    elif phase==\"eval\": model.eval()\n",
    "\n",
    "    ttl = 0\n",
    "    with torch.autograd.set_grad_enabled(phase==\"train\"):\n",
    "        for i, (input, target) in tqdm(enumerate(loader), total=len(loader)):\n",
    "            input = input.to(device=device)\n",
    "            target = target.to(device=device)\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "            loss_sum += loss.cpu().item() * input.size(0)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "            ttl += input.size()[0]\n",
    "\n",
    "            if phase==\"train\":\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "    correct = correct.cpu().item()\n",
    "    return {\n",
    "        'loss': loss_sum / float(ttl),\n",
    "        'accuracy': correct / float(ttl) * 100.0,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training in floating point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:45<00:00, 20.78it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 54.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "{'loss': 0.13607263702514272, 'accuracy': 95.73166666666667}\n",
      "{'loss': 0.05042032431769185, 'accuracy': 98.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [00:45<00:00, 20.40it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "{'loss': 0.04660116978312532, 'accuracy': 98.605}\n",
      "{'loss': 0.039288322220509875, 'accuracy': 98.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [00:45<00:00, 23.20it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 59.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2\n",
      "{'loss': 0.03134131622233351, 'accuracy': 99.08500000000001}\n",
      "{'loss': 0.027584416901902296, 'accuracy': 99.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [00:46<00:00, 20.38it/s]\n",
      "100%|██████████| 157/157 [00:04<00:00, 34.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3\n",
      "{'loss': 0.025083318675485983, 'accuracy': 99.23166666666667}\n",
      "{'loss': 0.0312590452823526, 'accuracy': 99.00999999999999}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [00:43<00:00, 23.78it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 64.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4\n",
      "{'loss': 0.019749159859724266, 'accuracy': 99.37166666666667}\n",
      "{'loss': 0.027827660323987948, 'accuracy': 99.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [00:42<00:00, 22.03it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5\n",
      "{'loss': 0.017655720647089767, 'accuracy': 99.44666666666667}\n",
      "{'loss': 0.029938086311386725, 'accuracy': 99.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [00:42<00:00, 25.24it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 52.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6\n",
      "{'loss': 0.009839267661239137, 'accuracy': 99.69333333333333}\n",
      "{'loss': 0.027093405548988175, 'accuracy': 99.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [00:42<00:00, 22.11it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 56.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7\n",
      "{'loss': 0.012126508988343995, 'accuracy': 99.6}\n",
      "{'loss': 0.03689758545774057, 'accuracy': 99.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [00:41<00:00, 22.62it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 66.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8\n",
      "{'loss': 0.012339169164924049, 'accuracy': 99.625}\n",
      "{'loss': 0.029518506918489038, 'accuracy': 99.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [00:40<00:00, 23.23it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 64.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9\n",
      "{'loss': 0.01024819865362612, 'accuracy': 99.68666666666667}\n",
      "{'loss': 0.02382945015741957, 'accuracy': 99.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(mxepochs):\n",
    "    fp_train_res = run_epoch(loaders['train'], model, F.cross_entropy,\n",
    "                            optimizer=optimizer, phase=\"train\")\n",
    "    fp_test_res = run_epoch(loaders['test'], model, F.cross_entropy,\n",
    "                            optimizer=optimizer, phase=\"eval\")\n",
    "    print('epoch', epoch)\n",
    "    print(fp_train_res)\n",
    "    print(fp_test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Block Floating Point Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do it with low precision arithmetic. We first define the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define two number formats, one low precision the other high\n",
    "lowp = BlockFloatingPoint(wl=8, dim=-1)   \n",
    "highp = FloatingPoint(exp=8, man=7)      # this is bfloat16\n",
    "\n",
    "# define quantization functions\n",
    "weight_quant = Quantizer(forward_number=lowp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
    "grad_quant = Quantizer(forward_number=lowp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"stochastic\")\n",
    "momentum_quant = Quantizer(forward_number=highp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"stochastic\")\n",
    "acc_quant = Quantizer(forward_number=highp, backward_number=None,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
    "\n",
    "# define a lambda function so that the Quantizer module can be duplicated easily\n",
    "act_error_quant = lambda : Quantizer(forward_number=lowp, backward_number=lowp,\n",
    "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the network. In the definition, we insert quantization module after every convolution layer. Note that the quantization of weight, gradient, momentum, and gradient accumulator are not handled here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define the model we are using\n",
    "class lp_Net(nn.Module):\n",
    "    def __init__(self, quant=None):\n",
    "        super(lp_Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        self.quant = quant()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.quant(x)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = self.quant(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.quant(x)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = self.quant(x)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.quant(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.quant(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [02:34<00:00,  6.69it/s]\n",
      "100%|██████████| 157/157 [00:08<00:00, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "{'loss': 0.13196566676584384, 'accuracy': 95.94500000000001}\n",
      "{'loss': 0.0466696068122983, 'accuracy': 98.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:36<00:00,  6.88it/s]\n",
      "100%|██████████| 157/157 [00:08<00:00, 19.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "{'loss': 0.044269972011664264, 'accuracy': 98.605}\n",
      "{'loss': 0.0340605054948479, 'accuracy': 98.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:33<00:00,  6.92it/s]\n",
      "100%|██████████| 157/157 [00:08<00:00, 18.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2\n",
      "{'loss': 0.028071887739025986, 'accuracy': 99.08666666666667}\n",
      "{'loss': 0.041074718202487565, 'accuracy': 98.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:28<00:00,  7.03it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3\n",
      "{'loss': 0.021294757222306605, 'accuracy': 99.355}\n",
      "{'loss': 0.03341474033953273, 'accuracy': 98.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:27<00:00,  7.03it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4\n",
      "{'loss': 0.015468017672479618, 'accuracy': 99.53833333333333}\n",
      "{'loss': 0.03446901559790422, 'accuracy': 98.96000000000001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:28<00:00,  6.87it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 22.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5\n",
      "{'loss': 0.013761486605556759, 'accuracy': 99.55666666666667}\n",
      "{'loss': 0.0318010430190916, 'accuracy': 99.11999999999999}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:28<00:00,  7.08it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 22.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6\n",
      "{'loss': 0.009867132546248224, 'accuracy': 99.68166666666667}\n",
      "{'loss': 0.034100452099219185, 'accuracy': 99.03999999999999}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:27<00:00,  7.03it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7\n",
      "{'loss': 0.011455022966711356, 'accuracy': 99.63}\n",
      "{'loss': 0.036446592486812736, 'accuracy': 98.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:27<00:00,  7.05it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8\n",
      "{'loss': 0.009812804903862223, 'accuracy': 99.69}\n",
      "{'loss': 0.03113835411135991, 'accuracy': 99.22999999999999}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 938/938 [02:09<00:00,  7.26it/s]\n",
      "100%|██████████| 157/157 [00:05<00:00, 26.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9\n",
      "{'loss': 0.006254680718504824, 'accuracy': 99.81333333333333}\n",
      "{'loss': 0.03364552705139886, 'accuracy': 99.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "use_cuda = False\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = lp_Net(act_error_quant).to(device)\n",
    "optimizer = SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=1e-4)\n",
    "lp_optimizer = OptimLP(optimizer,\n",
    "                    weight_quant=weight_quant,\n",
    "                    grad_quant=grad_quant,\n",
    "                    momentum_quant=momentum_quant,\n",
    "                    acc_quant=acc_quant\n",
    ")\n",
    "for epoch in range(mxepochs):\n",
    "    train_res = run_epoch(loaders['train'], model, F.cross_entropy,\n",
    "                                optimizer=lp_optimizer, phase=\"train\")\n",
    "    test_res = run_epoch(loaders['test'], model, F.cross_entropy,\n",
    "                                optimizer=lp_optimizer, phase=\"eval\")\n",
    "    print('epoch', epoch)\n",
    "    print(train_res)\n",
    "    print(test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Accuracy vs wordlength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, generate a plot of accuracy vs wordlength using the implementation given in the previous sections as a starting point. What precision gives the best accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute NN accuracy vs wordlength. Place appropriate code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 90.1), (2, 90.2), (3, 90.3), (4, 90.4), (5, 90.5), (6, 90.6), (7, 90.7), (8, 90.8)]\n"
     ]
    }
   ],
   "source": [
    "# dummy code here that just populates the res list\n",
    "res = []\n",
    "(minp, maxp) = (1,8)\n",
    "for i in range(minp, maxp+1):\n",
    "    res.append((i, 90 + i / 10))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a scatterplot of the results, also draw a line to show the floating point result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1201e3a90>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_res=np.array(res)\n",
    "plt.plot(plt_res[:,0], plt_res[:,1], 'x')\n",
    "plt.plot((minp,maxp),(fp_test_res['accuracy'], fp_test_res['accuracy']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total execution time (s): 2124.912360906601\n"
     ]
    }
   ],
   "source": [
    "print(\"Total execution time (s):\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
